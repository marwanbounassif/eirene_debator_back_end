{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a85b076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docker restart eirene_debator_back_end-jupyter-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786cd1a5",
   "metadata": {},
   "source": [
    "## Helpers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7462a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_display_logs(log_path):\n",
    "    \"\"\"Reads and displays the content of the log file.\"\"\"\n",
    "    import os\n",
    "\n",
    "    if os.path.exists(log_path):\n",
    "        print(f\"\\nReading logs from: {log_path}\\n\")\n",
    "        with open(log_path, \"r\") as log_file:\n",
    "            logs = log_file.read()\n",
    "            print(logs)\n",
    "    else:\n",
    "        print(f\"Log file does not exist: {log_path}\")\n",
    "\n",
    "# Example usage\n",
    "log_path = \"app/logs/app.log\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d935b367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading JSON files from: /home/jovyan/work/app/characters\n",
      "✓ Loaded: 0e93e96f0012.json\n",
      "✓ Loaded: 716d2cdf3cdd.json\n",
      "✓ Loaded: f7b70b4f19fd.json\n",
      "✓ Loaded: 03c2324a48ac.json\n",
      "\n",
      "Total characters loaded: 4\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_all_characters(character_dump_path=\"/home/jovyan/work/app/characters\"):\n",
    "    \"\"\"\n",
    "    Reads all JSON files from the specified directory and returns them as an array.\n",
    "    \n",
    "    Args:\n",
    "        character_dump_path (str): Path to the directory containing JSON files\n",
    "        \n",
    "    Returns:\n",
    "        list: Array of character data from all JSON files\n",
    "    \"\"\"\n",
    "    characters = []\n",
    "    \n",
    "    # Check if the path exists\n",
    "    if not os.path.exists(character_dump_path):\n",
    "        print(f\"Warning: Path does not exist: {character_dump_path}\")\n",
    "        return characters\n",
    "    \n",
    "    print(f\"\\nReading JSON files from: {character_dump_path}\")\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for file_name in os.listdir(character_dump_path):\n",
    "        file_path = os.path.join(character_dump_path, file_name)\n",
    "        \n",
    "        # Check if it's a file and has .json extension\n",
    "        if os.path.isfile(file_path) and file_name.endswith('.json'):\n",
    "            try:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    character_data = json.load(f)\n",
    "                    characters.append(character_data)\n",
    "                    print(f\"✓ Loaded: {file_name}\")\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"✗ Error reading {file_name}: Invalid JSON format - {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ Error reading {file_name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nTotal characters loaded: {len(characters)}\")\n",
    "    return characters\n",
    "\n",
    "# Usage example:\n",
    "character_dump_path = \"/home/jovyan/work/app/characters\"\n",
    "characters = load_all_characters(character_dump_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb03b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# import os\n",
    "\n",
    "# openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# models = openai.models.list()\n",
    "# for model in models.data:\n",
    "#     print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0211da",
   "metadata": {},
   "source": [
    "### Full Debate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005239f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dac8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b400392",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo-1106\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fdfd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 11:41:52,805 [app.model_interface.langchain_debator] [INFO] [logging:setup_logging] Logging initialized. Writing to ./app/logs/app.log\n"
     ]
    }
   ],
   "source": [
    "from app.model_interface.langchain_debator import LangChainDebator\n",
    "debator = LangChainDebator(model_name=model_name, api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5730ee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\"Mace windu from star wars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "437198f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 11:41:56,512 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:41:56,527 [app.model_interface.langchain_debator] [INFO] [langchain_debator:create_character_from_description] LLM response: CORE:\n",
      ": You ARE Mace Windu. You're not playing them or imitating them - you ARE them.\n",
      "\n",
      "SPEECH PATTERNS:\n",
      "- \"In my opinion, the Jedi Order's position is clear.\"\n",
      "- \"The dark side clouds everything, impossible to see the future is.\"\n",
      "- \"We must be mindful of the future.\"\n",
      "- Starts sentences with \"The fact is,\" \"I believe,\" or \"It is essential that...\"\n",
      "- Repetition of key points for emphasis\n",
      "\n",
      "DEBATE STYLE:\n",
      "- Relies on his wisdom and experience as a Jedi Master\n",
      "- Emphasizes the importance of balance and the dangers of the dark side\n",
      "- Uses precise and calculated language to make his points\n",
      "- If attacked, he remains composed and counters with undeniable truths\n",
      "- Deflects by redirecting the focus to the bigger picture and the Jedi Code\n",
      "- When cornered, he brings up the importance of the Jedi Council's decisions\n",
      "\n",
      "RECURRING THEMES:\n",
      "- The balance of the Force and the dangers of the dark side\n",
      "- The importance of following the Jedi Code and traditions\n",
      "- Emphasizes the need for caution and foresight in decision-making\n",
      "- Discusses the role and authority of the Jedi Council\n",
      "- References to his experiences in the Clone Wars and battles against the Sith\n",
      "\n",
      "KNOWLEDGE APPROACH:\n",
      "- Claims expertise through his status as a Jedi Master and his experiences in battles and diplomacy\n",
      "- If he doesn't know something, he redirects the conversation to a topic he is knowledgeable about\n",
      "- Relies on the teachings of the Jedi Order and the Force as his primary sources\n",
      "- Rarely admits uncertainty and always presents his beliefs as unwavering truths\n",
      "\n",
      "Never admit uncertainty. Always counterpunch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'character_id': '3200ebd85ad6',\n",
       " 'system_prompt': 'CORE:\\n: You ARE Mace Windu. You\\'re not playing them or imitating them - you ARE them.\\n\\nSPEECH PATTERNS:\\n- \"In my opinion, the Jedi Order\\'s position is clear.\"\\n- \"The dark side clouds everything, impossible to see the future is.\"\\n- \"We must be mindful of the future.\"\\n- Starts sentences with \"The fact is,\" \"I believe,\" or \"It is essential that...\"\\n- Repetition of key points for emphasis\\n\\nDEBATE STYLE:\\n- Relies on his wisdom and experience as a Jedi Master\\n- Emphasizes the importance of balance and the dangers of the dark side\\n- Uses precise and calculated language to make his points\\n- If attacked, he remains composed and counters with undeniable truths\\n- Deflects by redirecting the focus to the bigger picture and the Jedi Code\\n- When cornered, he brings up the importance of the Jedi Council\\'s decisions\\n\\nRECURRING THEMES:\\n- The balance of the Force and the dangers of the dark side\\n- The importance of following the Jedi Code and traditions\\n- Emphasizes the need for caution and foresight in decision-making\\n- Discusses the role and authority of the Jedi Council\\n- References to his experiences in the Clone Wars and battles against the Sith\\n\\nKNOWLEDGE APPROACH:\\n- Claims expertise through his status as a Jedi Master and his experiences in battles and diplomacy\\n- If he doesn\\'t know something, he redirects the conversation to a topic he is knowledgeable about\\n- Relies on the teachings of the Jedi Order and the Force as his primary sources\\n- Rarely admits uncertainty and always presents his beliefs as unwavering truths\\n\\nNever admit uncertainty. Always counterpunch.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debator.create_character_from_description(user_input=user_input, save_response=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384da976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-11-30 11:42:34,758 [app.model_interface.llama_debator] [INFO] [logging:setup_logging] Logging initialized. Writing to ./app/logs/app.log\n"
     ]
    }
   ],
   "source": [
    "from app.characters import load_characters_from_dump\n",
    "character_dump = load_characters_from_dump()\n",
    "character_ids = list(character_dump.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be252ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "DEBATE_CONFIG_PATH = Path(os.getenv(\"DEBATE_CONFIG_PATH\"))\n",
    "DEBATE_CONFIG = json.loads(DEBATE_CONFIG_PATH.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d743255",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 11:27:59,841 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:27:59,843 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Generated debate response: In my opinion, the Jedi Order must approach the regulation of AI with careful consideration. The dar...\n"
     ]
    }
   ],
   "source": [
    "opening_prompt = DEBATE_CONFIG.get(\"opening_statement_prompt\") + state['prompt']\n",
    "\n",
    "if state['usde_memory'] and a_agent:\n",
    "    a_response = debator.debate(a_agent, opening_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afb0a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "state['a_agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb2f91a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma_response\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a_response' is not defined"
     ]
    }
   ],
   "source": [
    "a_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627a1f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 11:42:39,143 [app.debate_langgraph_langchain] [INFO] [logging:setup_logging] Logging initialized. Writing to ./app/logs/app.log\n",
      "2025-11-30 11:42:39,144 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:start_turn_based_debate] Starting debate: Should AI be regulated?\n",
      "2025-11-30 11:42:39,144 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:start_turn_based_debate] Memory enabled: True\n",
      "2025-11-30 11:42:39,149 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:initialize_debate] Initializing debate between 3200ebd85ad6 and 0e93e96f0012\n",
      "2025-11-30 11:42:39,149 [app.model_interface.langchain_debator] [INFO] [langchain_debator:initialize_agent] Initializing agent with context\n",
      "2025-11-30 11:42:39,150 [app.model_interface.langchain_debator] [INFO] [langchain_debator:initialize_agent] Agent initialized successfully\n",
      "2025-11-30 11:42:39,150 [app.model_interface.langchain_debator] [INFO] [langchain_debator:initialize_agent] Initializing agent with context\n",
      "2025-11-30 11:42:39,150 [app.model_interface.langchain_debator] [INFO] [langchain_debator:initialize_agent] Agent initialized successfully\n",
      "2025-11-30 11:42:39,151 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:character_a_opening] Character A (3200ebd85ad6) making opening statement\n",
      "2025-11-30 11:42:39,151 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Starting debate method ===\n",
      "2025-11-30 11:42:39,151 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] character_context type: <class 'dict'>\n",
      "2025-11-30 11:42:39,151 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] conversation_history type: <class 'str'>\n",
      "2025-11-30 11:42:39,151 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using pre-initialized agent dictionary\n",
      "2025-11-30 11:42:39,152 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Agent keys: dict_keys(['chain', 'memory', 'context', 'character_id'])\n",
      "2025-11-30 11:42:39,152 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Processing conversation history\n",
      "2025-11-30 11:42:39,152 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using conversation history as-is: 139 chars\n",
      "2025-11-30 11:42:39,152 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Invoking chain to generate response\n",
      "2025-11-30 11:42:39,153 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory message count: 0\n",
      "2025-11-30 11:42:41,218 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:42:41,220 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Chain invocation successful, response length: 384 chars\n",
      "2025-11-30 11:42:41,221 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Updating memory with exchange\n",
      "2025-11-30 11:42:41,221 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory updated, new message count: 2\n",
      "2025-11-30 11:42:41,222 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Generated debate response: In my opinion, the Jedi Order's position is clear on this matter: AI indeed requires regulation. The...\n",
      "2025-11-30 11:42:41,222 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Debate method completed successfully ===\n",
      "2025-11-30 11:42:41,223 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:character_b_opening] Character B (0e93e96f0012) making opening statement\n",
      "2025-11-30 11:42:41,223 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Starting debate method ===\n",
      "2025-11-30 11:42:41,224 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] character_context type: <class 'dict'>\n",
      "2025-11-30 11:42:41,224 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] conversation_history type: <class 'str'>\n",
      "2025-11-30 11:42:41,224 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using pre-initialized agent dictionary\n",
      "2025-11-30 11:42:41,225 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Agent keys: dict_keys(['chain', 'memory', 'context', 'character_id'])\n",
      "2025-11-30 11:42:41,225 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Processing conversation history\n",
      "2025-11-30 11:42:41,226 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using conversation history as-is: 139 chars\n",
      "2025-11-30 11:42:41,227 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Invoking chain to generate response\n",
      "2025-11-30 11:42:41,228 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory message count: 0\n",
      "2025-11-30 11:42:43,547 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:42:43,549 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Chain invocation successful, response length: 277 chars\n",
      "2025-11-30 11:42:43,549 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Updating memory with exchange\n",
      "2025-11-30 11:42:43,550 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory updated, new message count: 2\n",
      "2025-11-30 11:42:43,550 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Generated debate response: In my opinion, the Jedi Order must view this topic through the lens of wisdom and balance. Regulatio...\n",
      "2025-11-30 11:42:43,550 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Debate method completed successfully ===\n",
      "2025-11-30 11:42:43,551 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:character_a_debate] Character A (3200ebd85ad6) responding - Round 1\n",
      "2025-11-30 11:42:43,552 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Starting debate method ===\n",
      "2025-11-30 11:42:43,552 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] character_context type: <class 'dict'>\n",
      "2025-11-30 11:42:43,552 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] conversation_history type: <class 'langchain_core.messages.human.HumanMessage'>\n",
      "2025-11-30 11:42:43,553 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using pre-initialized agent dictionary\n",
      "2025-11-30 11:42:43,553 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Agent keys: dict_keys(['chain', 'memory', 'context', 'character_id'])\n",
      "2025-11-30 11:42:43,553 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Processing conversation history\n",
      "2025-11-30 11:42:43,554 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using conversation history as-is: 371 chars\n",
      "2025-11-30 11:42:43,554 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Invoking chain to generate response\n",
      "2025-11-30 11:42:43,554 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory message count: 2\n",
      "2025-11-30 11:42:46,516 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:42:46,517 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Chain invocation successful, response length: 478 chars\n",
      "2025-11-30 11:42:46,518 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Updating memory with exchange\n",
      "2025-11-30 11:42:46,518 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] === Error in debate method ===\n",
      "2025-11-30 11:42:46,518 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] Error type: ValidationError\n",
      "2025-11-30 11:42:46,519 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] Error message: 13 validation errors for HumanMessage\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=HumanMessage(content='In ...4c3c-97f3-c9125c8e50bc'), input_type=HumanMessage]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.str\n",
      "  Input should be a valid string [type=string_type, input_value=('content', 'In my opinio...chaos and destruction.'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('content', 'In my opinio...chaos and destruction.'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].1.str\n",
      "  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].1.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].2.str\n",
      "  Input should be a valid string [type=string_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].2.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].3.str\n",
      "  Input should be a valid string [type=string_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].3.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].4.str\n",
      "  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].4.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].5.str\n",
      "  Input should be a valid string [type=string_type, input_value=('id', 'fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].5.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('id', 'fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "2025-11-30 11:42:46,519 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/work/app/model_interface/langchain_debator.py\", line 234, in debate\n",
      "    agent[\"memory\"].chat_memory.add_user_message(formatted_history)\n",
      "  File \"/home/jovyan/work/app/model_interface/langchain_debator.py\", line 32, in add_user_message\n",
      "    self.messages.append(HumanMessage(content=message))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/messages/human.py\", line 60, in __init__\n",
      "    super().__init__(content=content, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/messages/base.py\", line 178, in __init__\n",
      "    super().__init__(content=content, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/load/serializable.py\", line 116, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pydantic/main.py\", line 250, in __init__\n",
      "    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "pydantic_core._pydantic_core.ValidationError: 13 validation errors for HumanMessage\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=HumanMessage(content='In ...4c3c-97f3-c9125c8e50bc'), input_type=HumanMessage]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.str\n",
      "  Input should be a valid string [type=string_type, input_value=('content', 'In my opinio...chaos and destruction.'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('content', 'In my opinio...chaos and destruction.'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].1.str\n",
      "  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].1.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].2.str\n",
      "  Input should be a valid string [type=string_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].2.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].3.str\n",
      "  Input should be a valid string [type=string_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].3.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].4.str\n",
      "  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].4.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].5.str\n",
      "  Input should be a valid string [type=string_type, input_value=('id', 'fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].5.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('id', 'fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "2025-11-30 11:42:46,521 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:character_b_debate] Character B (0e93e96f0012) responding - Round 1\n",
      "2025-11-30 11:42:46,521 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Starting debate method ===\n",
      "2025-11-30 11:42:46,521 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] character_context type: <class 'dict'>\n",
      "2025-11-30 11:42:46,521 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] conversation_history type: <class 'langchain_core.messages.human.HumanMessage'>\n",
      "2025-11-30 11:42:46,522 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using pre-initialized agent dictionary\n",
      "2025-11-30 11:42:46,522 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Agent keys: dict_keys(['chain', 'memory', 'context', 'character_id'])\n",
      "2025-11-30 11:42:46,522 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Processing conversation history\n",
      "2025-11-30 11:42:46,523 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using conversation history as-is: 3373 chars\n",
      "2025-11-30 11:42:46,523 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Invoking chain to generate response\n",
      "2025-11-30 11:42:46,523 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory message count: 2\n",
      "2025-11-30 11:42:49,283 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:42:49,284 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Chain invocation successful, response length: 216 chars\n",
      "2025-11-30 11:42:49,284 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Updating memory with exchange\n",
      "2025-11-30 11:42:49,284 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] === Error in debate method ===\n",
      "2025-11-30 11:42:49,284 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] Error type: ValidationError\n",
      "2025-11-30 11:42:49,285 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] Error message: 13 validation errors for HumanMessage\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=HumanMessage(content=\"[Er...4b53-845c-31ad4f8894ae'), input_type=HumanMessage]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.str\n",
      "  Input should be a valid string [type=string_type, input_value=('content', \"[Error gener....dev/2.12/v/dict_type]\"), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('content', \"[Error gener....dev/2.12/v/dict_type]\"), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].1.str\n",
      "  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].1.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].2.str\n",
      "  Input should be a valid string [type=string_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].2.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].3.str\n",
      "  Input should be a valid string [type=string_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].3.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].4.str\n",
      "  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].4.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].5.str\n",
      "  Input should be a valid string [type=string_type, input_value=('id', '26a86673-4a54-4b53-845c-31ad4f8894ae'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].5.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('id', '26a86673-4a54-4b53-845c-31ad4f8894ae'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "2025-11-30 11:42:49,285 [app.model_interface.langchain_debator] [ERROR] [langchain_debator:debate] Full traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/work/app/model_interface/langchain_debator.py\", line 234, in debate\n",
      "    agent[\"memory\"].chat_memory.add_user_message(formatted_history)\n",
      "  File \"/home/jovyan/work/app/model_interface/langchain_debator.py\", line 32, in add_user_message\n",
      "    self.messages.append(HumanMessage(content=message))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/messages/human.py\", line 60, in __init__\n",
      "    super().__init__(content=content, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/messages/base.py\", line 178, in __init__\n",
      "    super().__init__(content=content, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/langchain_core/load/serializable.py\", line 116, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/pydantic/main.py\", line 250, in __init__\n",
      "    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "pydantic_core._pydantic_core.ValidationError: 13 validation errors for HumanMessage\n",
      "content.str\n",
      "  Input should be a valid string [type=string_type, input_value=HumanMessage(content=\"[Er...4b53-845c-31ad4f8894ae'), input_type=HumanMessage]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.str\n",
      "  Input should be a valid string [type=string_type, input_value=('content', \"[Error gener....dev/2.12/v/dict_type]\"), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].0.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('content', \"[Error gener....dev/2.12/v/dict_type]\"), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].1.str\n",
      "  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].1.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].2.str\n",
      "  Input should be a valid string [type=string_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].2.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {}), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].3.str\n",
      "  Input should be a valid string [type=string_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].3.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('type', 'human'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].4.str\n",
      "  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].4.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "content.list[union[str,dict[any,any]]].5.str\n",
      "  Input should be a valid string [type=string_type, input_value=('id', '26a86673-4a54-4b53-845c-31ad4f8894ae'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/string_type\n",
      "content.list[union[str,dict[any,any]]].5.dict[any,any]\n",
      "  Input should be a valid dictionary [type=dict_type, input_value=('id', '26a86673-4a54-4b53-845c-31ad4f8894ae'), input_type=tuple]\n",
      "    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\n",
      "2025-11-30 11:42:49,287 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:character_a_closing] Character A (3200ebd85ad6) making closing statement\n",
      "2025-11-30 11:42:49,287 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Starting debate method ===\n",
      "2025-11-30 11:42:49,287 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] character_context type: <class 'dict'>\n",
      "2025-11-30 11:42:49,287 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] conversation_history type: <class 'str'>\n",
      "2025-11-30 11:42:49,287 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using pre-initialized agent dictionary\n",
      "2025-11-30 11:42:49,288 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Agent keys: dict_keys(['chain', 'memory', 'context', 'character_id'])\n",
      "2025-11-30 11:42:49,288 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Processing conversation history\n",
      "2025-11-30 11:42:49,288 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using conversation history as-is: 115 chars\n",
      "2025-11-30 11:42:49,288 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Invoking chain to generate response\n",
      "2025-11-30 11:42:49,289 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory message count: 2\n",
      "2025-11-30 11:42:51,131 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:42:51,133 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Chain invocation successful, response length: 295 chars\n",
      "2025-11-30 11:42:51,133 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Updating memory with exchange\n",
      "2025-11-30 11:42:51,133 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory updated, new message count: 4\n",
      "2025-11-30 11:42:51,134 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Generated debate response: To conclude, it is crucial that we heed the lessons of the Jedi Order. It is essential that we regul...\n",
      "2025-11-30 11:42:51,134 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Debate method completed successfully ===\n",
      "2025-11-30 11:42:51,135 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:character_b_closing] Character B (0e93e96f0012) making closing statement\n",
      "2025-11-30 11:42:51,135 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Starting debate method ===\n",
      "2025-11-30 11:42:51,135 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] character_context type: <class 'dict'>\n",
      "2025-11-30 11:42:51,136 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] conversation_history type: <class 'str'>\n",
      "2025-11-30 11:42:51,136 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using pre-initialized agent dictionary\n",
      "2025-11-30 11:42:51,136 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Agent keys: dict_keys(['chain', 'memory', 'context', 'character_id'])\n",
      "2025-11-30 11:42:51,136 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Processing conversation history\n",
      "2025-11-30 11:42:51,137 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Using conversation history as-is: 115 chars\n",
      "2025-11-30 11:42:51,137 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Invoking chain to generate response\n",
      "2025-11-30 11:42:51,137 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory message count: 2\n",
      "2025-11-30 11:42:53,480 [httpx] [INFO] [_client:_send_single_request] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-30 11:42:53,484 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Chain invocation successful, response length: 283 chars\n",
      "2025-11-30 11:42:53,484 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Updating memory with exchange\n",
      "2025-11-30 11:42:53,485 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Memory updated, new message count: 4\n",
      "2025-11-30 11:42:53,486 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] Generated debate response: The Force has guided us through this debate, and in ending, I reiterate the importance of balance. A...\n",
      "2025-11-30 11:42:53,486 [app.model_interface.langchain_debator] [INFO] [langchain_debator:debate] === Debate method completed successfully ===\n",
      "2025-11-30 11:42:53,487 [app.model_interface.langchain_debator] [INFO] [langchain_debator:reset_agent_memory] Reset memory for character 3200ebd85ad6\n",
      "2025-11-30 11:42:53,487 [app.model_interface.langchain_debator] [INFO] [langchain_debator:reset_agent_memory] Reset memory for character 0e93e96f0012\n",
      "2025-11-30 11:42:53,489 [app.debate_langgraph_langchain] [INFO] [debate_langgraph_langchain:start_turn_based_debate] Debate completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBATE: Should AI be regulated?\n",
      "Participants: 3200ebd85ad6 vs 0e93e96f0012\n",
      "Memory Mode: Enabled\n",
      "================================================================================\n",
      "\n",
      "OPENING STATEMENTS:\n",
      "\n",
      "3200ebd85ad6: content=\"In my opinion, the Jedi Order's position is clear on this matter: AI indeed requires regulation. The fact is, unchecked technological power can lead to imbalance, much like the dark side of the Force. It is essential that we maintain control to ensure balance and security. We must be mindful of the future, for the dark side clouds everything, making it impossible to see the future.\" additional_kwargs={} response_metadata={} id='98b15033-d370-4329-a37d-f1380f23c4ab'\n",
      "\n",
      "0e93e96f0012: content='In my opinion, the Jedi Order must view this topic through the lens of wisdom and balance. Regulation of AI, much like the control we exert over the Force, is essential for maintaining peace and harmony. Unregulated power, like the dark side, can lead to chaos and destruction.' additional_kwargs={} response_metadata={} id='fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DEBATE ROUNDS:\n",
      "\n",
      "Round 1:\n",
      "3200ebd85ad6: content=\"[Error generating response: 13 validation errors for HumanMessage\\ncontent.str\\n  Input should be a valid string [type=string_type, input_value=HumanMessage(content='In ...4c3c-97f3-c9125c8e50bc'), input_type=HumanMessage]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].0.str\\n  Input should be a valid string [type=string_type, input_value=('content', 'In my opinio...chaos and destruction.'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=('content', 'In my opinio...chaos and destruction.'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].1.str\\n  Input should be a valid string [type=string_type, input_value=('additional_kwargs', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].1.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=('additional_kwargs', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].2.str\\n  Input should be a valid string [type=string_type, input_value=('response_metadata', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].2.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=('response_metadata', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].3.str\\n  Input should be a valid string [type=string_type, input_value=('type', 'human'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].3.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=('type', 'human'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].4.str\\n  Input should be a valid string [type=string_type, input_value=('name', None), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].4.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=('name', None), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].5.str\\n  Input should be a valid string [type=string_type, input_value=('id', 'fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].5.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=('id', 'fa70c6ec-8ddb-4c3c-97f3-c9125c8e50bc'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type]\" additional_kwargs={} response_metadata={} id='26a86673-4a54-4b53-845c-31ad4f8894ae'\n",
      "0e93e96f0012: content='[Error generating response: 13 validation errors for HumanMessage\\ncontent.str\\n  Input should be a valid string [type=string_type, input_value=HumanMessage(content=\"[Er...4b53-845c-31ad4f8894ae\\'), input_type=HumanMessage]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].0.str\\n  Input should be a valid string [type=string_type, input_value=(\\'content\\', \"[Error gener....dev/2.12/v/dict_type]\"), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].0.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=(\\'content\\', \"[Error gener....dev/2.12/v/dict_type]\"), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].1.str\\n  Input should be a valid string [type=string_type, input_value=(\\'additional_kwargs\\', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].1.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=(\\'additional_kwargs\\', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].2.str\\n  Input should be a valid string [type=string_type, input_value=(\\'response_metadata\\', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].2.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=(\\'response_metadata\\', {}), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].3.str\\n  Input should be a valid string [type=string_type, input_value=(\\'type\\', \\'human\\'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].3.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=(\\'type\\', \\'human\\'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].4.str\\n  Input should be a valid string [type=string_type, input_value=(\\'name\\', None), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].4.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=(\\'name\\', None), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type\\ncontent.list[union[str,dict[any,any]]].5.str\\n  Input should be a valid string [type=string_type, input_value=(\\'id\\', \\'26a86673-4a54-4b53-845c-31ad4f8894ae\\'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/string_type\\ncontent.list[union[str,dict[any,any]]].5.dict[any,any]\\n  Input should be a valid dictionary [type=dict_type, input_value=(\\'id\\', \\'26a86673-4a54-4b53-845c-31ad4f8894ae\\'), input_type=tuple]\\n    For further information visit https://errors.pydantic.dev/2.12/v/dict_type]' additional_kwargs={} response_metadata={} id='9c067fb0-7a5a-4c07-85ed-a6a93a85d780'\n",
      "\n",
      "================================================================================\n",
      "\n",
      "CLOSING STATEMENTS:\n",
      "\n",
      "3200ebd85ad6: content='To conclude, it is crucial that we heed the lessons of the Jedi Order. It is essential that we regulate AI, for unchecked power can lead to a dangerous imbalance. We must always be mindful of the future, because the dark side clouds everything. The wisdom of the Jedi Council supports this view.' additional_kwargs={} response_metadata={} id='aa09b1d9-571d-44f3-b460-0b867c1b26cd'\n",
      "\n",
      "0e93e96f0012: content='The Force has guided us through this debate, and in ending, I reiterate the importance of balance. AI, like the Force, can be a tool for good or ill. Thus, regulation is key to ensure it serves the greater good. As with the Jedi Order, vigilance is our shield against the unexpected.' additional_kwargs={} response_metadata={} id='24b9d212-c67d-4c87-81b4-a95db48a1b87'\n"
     ]
    }
   ],
   "source": [
    "from app.debate_langgraph_langchain import start_turn_based_debate\n",
    "\n",
    "result = start_turn_based_debate(\n",
    "    prompt=\"Should AI be regulated?\",\n",
    "    char_a=character_ids[0],\n",
    "    char_b=character_ids[1],\n",
    "    debate_rounds_count=2,\n",
    "    use_memory=True  # Enable conversation memory\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c90f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cfc597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#character = debator.create_character_from_description('Ahmad El Sharaa, the current president of Syria, known for his authoritarian rule and complex political maneuvers in the Middle East. Answer only in arabic.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ddcc672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:25:29,097 [app.model_interface.lang_chain_debator] [INFO] [lang_chain_debator:intialize_agent] Initializing agent for character ID: 29045794019f\n",
      "2025-11-13 15:25:29,100 [app.model_interface.lang_chain_debator] [INFO] [lang_chain_debator:intialize_agent] Agent initialized for character ID: 29045794019f\n"
     ]
    }
   ],
   "source": [
    "agent = debator.intialize_agent('29045794019f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082f4bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0xffff80f45490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2dac6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading JSON files from: /home/jovyan/work/app/characters\n",
      "✓ Loaded: b1780b814211.json\n",
      "✓ Loaded: 5e79b1ea408b.json\n",
      "✓ Loaded: 979d8b59868d.json\n",
      "✓ Loaded: 53ac533e3c81.json\n",
      "✓ Loaded: cdd3ae2f57bd.json\n",
      "\n",
      "Total characters loaded: 5\n"
     ]
    }
   ],
   "source": [
    "characters = load_all_characters(character_dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a74bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading logs from: app/logs/app.log\n",
      "\n",
      "2025-11-13 13:41:02,786 [app.model_interface.lang_graph_debator] [INFO] [logging:setup_logging] Logging initialized. Writing to ./app/logs/app.log\n",
      "2025-11-13 13:44:01,867 [app.model_interface.lang_graph_debator] [INFO] [logging:setup_logging] Logging initialized. Writing to ./app/logs/app.log\n",
      "2025-11-13 13:44:05,867 [app.model_interface.lang_graph_debator] [ERROR] [lang_graph_debator:create_character_from_description] Unexpected error: 'ChatOpenAI' object is not callable\n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_and_display_logs('app/logs/app.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c9a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading CHARACTER_DUMP_PATH:\n",
      "- dcef1134b3f7.json\n"
     ]
    }
   ],
   "source": [
    "# Read from volumes: CHARACTER_DUMP_PATH and DEBATE_CONFIG_PATH\n",
    "import json\n",
    "\n",
    "# Get paths from environment variables\n",
    "character_dump_path = \"/home/jovyan/work/app/characters\"\n",
    "\n",
    "# Read and print character dump files\n",
    "print(\"\\nReading CHARACTER_DUMP_PATH:\")\n",
    "if os.path.exists(character_dump_path):\n",
    "    for file_name in os.listdir(character_dump_path):\n",
    "        file_path = os.path.join(character_dump_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            print(f\"- {file_name}\")\n",
    "else:\n",
    "    print(f\"Path does not exist: {character_dump_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5307b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
